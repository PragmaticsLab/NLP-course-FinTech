{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Активное обучение $-$ класс алгоритмов обучения моделей машинного обучения. Алгоритмы активного обучения отличаются тем, могут интерактивно запрашивать пользователя (или некоторый другой источник информации) для разметки новых примеров данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"active_learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pool-Based Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом сценарии экземпляры извлекаются из всего пула данных и им присваивается информативная оценка, которая показывает, насколько хорошо текущий алгоритм «понимает» данные. \n",
    "\n",
    "Затем система выбираются и размечаются наиболее информативные примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncertainty sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В рамках этого алгоритма размечаются те примеры, на которых текущая модель наименее уверена.\n",
    "\n",
    "В качестве функций \"уверенности\" можно использовать вероятности классов или расстояния до разделяющей гиперплоскости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Membership Query Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь алгритм обучения модели генерирует свои собственные примеры из некоторого настраиваемого распределения. \n",
    "Эти сгенерированные примеры отправляются на разметку и модель дообучается с учетом разметки этих примеров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query by Committee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: построить ансамбль моделей $a_1,...,a_T$. \n",
    "\n",
    "Выбирать новые объекты $x_i$ с наибольшей несогласованностью решений ансамбля моделей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип максимума энтропии: выбираем $x_i$, на котором $a_t(x_i)$ максимально различны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип максимума средней $KL$-дивергенции:выбираем $x_i$ , на котором $P_t(y|x_i)$ максимально различны:\n",
    "\n",
    "$С(y|u) = \\frac{1}{T}\\sum_{t=1}^T P_t(y|u)$ - консенсус комитета "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM для Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые активные алгоритмы обучения построены на алгоритме SVM и используют структуру SVM для определения того, какие точки данных нужно размечать. \n",
    "\n",
    "SVM используется для определения уверенности модели в предсказании на каждом из примеров выборки. \n",
    "В качестве меры уверенности служит расстояние от объекта до построенной не текущей итерации разделяющей гиперплоскости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning for texts classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим алгоритм pool-based active learning на примере задачи классификации твитов по тональности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Разделить данные на X_pool (выборка, которую можно размечать) и X_test.\n",
    "2. Выбрать $k$ примеров из X_pool для начального X_train и разметить их. Остальные данные в X_pool $-$ валидационное множество. \n",
    "3. Обучить модель на  X_train.\n",
    "5. Сделать predict обученной моделью на X_pool, вычислить вероятности для каждого $x_i$.\n",
    "6. Вычислить качество работы модели на X_test.\n",
    "7. Выбрать $k$ наиболее информативных объектов из X_pool, основываясь на уверенности модели в каждом из объектов (например, вероятности классов).\n",
    "8. Переменести эти $k$ выбранных объектов в X_train.\n",
    "9. Если качество работы модели на X_test достаточное, то останавливаемся, иначе возвращаемся к шагу 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "# positive['label'] = ['positive'] * len(positive)\n",
    "# negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "# negative['label'] = ['negative'] * len(negative)\n",
    "# df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_text_classification_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [0 if category == 'ham' else 1 for category in df['Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence(class_probs):\n",
    "    return abs(0.5-class_probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      1072\n",
      "           1       0.30      0.98      0.45        43\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1115\n",
      "   macro avg       0.65      0.94      0.70      1115\n",
      "weighted avg       0.97      0.91      0.93      1115\n",
      "\n",
      "60 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1037\n",
      "           1       0.49      0.90      0.64        78\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1115\n",
      "   macro avg       0.74      0.91      0.80      1115\n",
      "weighted avg       0.96      0.93      0.94      1115\n",
      "\n",
      "70 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1012\n",
      "           1       0.65      0.90      0.76       103\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1115\n",
      "   macro avg       0.82      0.93      0.86      1115\n",
      "weighted avg       0.96      0.95      0.95      1115\n",
      "\n",
      "80 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1006\n",
      "           1       0.69      0.90      0.78       109\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1115\n",
      "   macro avg       0.84      0.93      0.88      1115\n",
      "weighted avg       0.96      0.95      0.95      1115\n",
      "\n",
      "90 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      1007\n",
      "           1       0.72      0.94      0.82       108\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1115\n",
      "   macro avg       0.86      0.95      0.90      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n",
      "100 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       994\n",
      "           1       0.80      0.93      0.86       121\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1115\n",
      "   macro avg       0.89      0.95      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "110 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       985\n",
      "           1       0.84      0.92      0.88       130\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1115\n",
      "   macro avg       0.91      0.95      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "120 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       988\n",
      "           1       0.85      0.95      0.90       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.92      0.97      0.94      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "130 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       979\n",
      "           1       0.89      0.93      0.91       136\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.94      0.96      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "140 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       981\n",
      "           1       0.87      0.93      0.90       134\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1115\n",
      "   macro avg       0.93      0.95      0.94      1115\n",
      "weighted avg       0.98      0.97      0.98      1115\n",
      "\n",
      "150 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       984\n",
      "           1       0.87      0.95      0.91       131\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.93      0.96      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "160 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       989\n",
      "           1       0.85      0.95      0.90       126\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1115\n",
      "   macro avg       0.92      0.97      0.94      1115\n",
      "weighted avg       0.98      0.97      0.98      1115\n",
      "\n",
      "170 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       988\n",
      "           1       0.86      0.96      0.91       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.93      0.97      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "180 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       983\n",
      "           1       0.88      0.95      0.91       132\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.94      0.96      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "190 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       984\n",
      "           1       0.89      0.96      0.92       131\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.94      0.97      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "200 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       988\n",
      "           1       0.87      0.98      0.92       127\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.94      0.98      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "210 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       984\n",
      "           1       0.90      0.98      0.94       131\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.95      0.98      0.96      1115\n",
      "weighted avg       0.99      0.98      0.99      1115\n",
      "\n",
      "220 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       986\n",
      "           1       0.89      0.98      0.93       129\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.94      0.98      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "230 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       986\n",
      "           1       0.89      0.98      0.94       129\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.95      0.98      0.96      1115\n",
      "weighted avg       0.99      0.98      0.99      1115\n",
      "\n",
      "240 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       983\n",
      "           1       0.92      0.98      0.95       132\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.96      0.99      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "250 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       982\n",
      "           1       0.92      0.98      0.95       133\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.96      0.99      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_size = 50\n",
    "\n",
    "dataset_size = X.shape[0]\n",
    "target_score = 0.95\n",
    "score = 0\n",
    "step = 10\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_pool = X[train_size:]\n",
    "y_pool = y[train_size:]\n",
    "\n",
    "scores = [0]\n",
    "train_szs = [0]\n",
    "\n",
    "while score < target_score and train_size <= dataset_size:\n",
    "    vec = CountVectorizer(ngram_range=(1, 1))\n",
    "    bow = vec.fit_transform(X_train)\n",
    "    clf = clf.fit(bow,y_train)\n",
    "    pred = clf.predict(vec.transform(X_test))\n",
    "    \n",
    "    print(\"{0} train samples\".format(train_size))\n",
    "    print(classification_report(pred, y_test))\n",
    "    score = f1_score(pred, y_test)\n",
    "    scores.append(score)\n",
    "    train_szs.append(train_size)\n",
    "    \n",
    "    pred_probs = clf.predict_proba(vec.transform(X_pool))\n",
    "    confidences = [get_confidence(probs) for probs in pred_probs]\n",
    "    \n",
    "    X_train = np.concatenate([X_train, X_pool[np.argsort(confidences)[:step]]])\n",
    "    y_train = np.concatenate([y_train, y_pool[np.argsort(confidences)[:step]]])\n",
    "    X_pool = X_pool[sorted(np.argsort(confidences)[step:])]\n",
    "    y_pool = y_pool[sorted(np.argsort(confidences)[step:])]\n",
    "    train_size += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457 train samples\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       986\n",
      "           1       0.91      1.00      0.95       129\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.95      0.99      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(X)\n",
    "clf = clf.fit(bow,y)\n",
    "pred = clf.predict(vec.transform(X_test))\n",
    "\n",
    "print(\"{0} train samples\".format(dataset_size))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a241b9748>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_szs,scores)\n",
    "plt.plot(train_szs, [0.95 for sz in train_szs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что для достижения лучшего качества на этом датасете дсотаточно обучиться на 300 правильно выбранных примерах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
